{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11001062,"sourceType":"datasetVersion","datasetId":6848286}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !rm -rf /kaggle/working/*\n!pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:30:03.535847Z","iopub.execute_input":"2025-05-07T20:30:03.536102Z","iopub.status.idle":"2025-05-07T20:30:04.131809Z","shell.execute_reply.started":"2025-05-07T20:30:03.536080Z","shell.execute_reply":"2025-05-07T20:30:04.130677Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\nimport os\nimport pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\n\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = AutoConfig.from_pretrained(model_name, num_labels=3)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T19:59:33.798092Z","iopub.execute_input":"2025-05-07T19:59:33.798446Z","iopub.status.idle":"2025-05-07T19:59:37.155758Z","shell.execute_reply.started":"2025-05-07T19:59:33.798407Z","shell.execute_reply":"2025-05-07T19:59:37.155126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a0c1d509c04e1c907f82af960c8257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e062f7c14f4879b5b9fa43c0dceae3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bad06fe8b774426f9a75a47ea3a5a329"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ab2232923bb4d1bab82821312a1a9ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e65c2254f3a4100adf1c7c373876f7f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/balanced-labeled-comments-dataset-int-csv\"))\nimport pandas as pd\n\ndframe = pd.read_csv(\"/kaggle/input/balanced-labeled-comments-dataset-int-csv/balanced_labeled_comments_dataset_int.csv\")\n\n\n# dframe['Classification'] = dframe['Classification'].map({\"Other\": 0, \"Suggestion\": 1})\n\n# Split the data\ntrain_df, temp_df = train_test_split(dframe, test_size=0.1, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n\n# Convert to Hugging Face Datasets\ntrain_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\ntest_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n\n# Create DatasetDict\ncategories = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})\n\ncategories","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T19:59:38.867321Z","iopub.execute_input":"2025-05-07T19:59:38.867608Z","iopub.status.idle":"2025-05-07T19:59:38.904210Z","shell.execute_reply.started":"2025-05-07T19:59:38.867585Z","shell.execute_reply":"2025-05-07T19:59:38.903342Z"}},"outputs":[{"name":"stdout","text":"['balanced_labeled_comments_dataset_int.csv']\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Comments', 'Classification'],\n        num_rows: 5400\n    })\n    validation: Dataset({\n        features: ['Comments', 'Classification'],\n        num_rows: 300\n    })\n    test: Dataset({\n        features: ['Comments', 'Classification'],\n        num_rows: 300\n    })\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Tokenize the datasets\ndef tokenize(batch):\n    return tokenizer(batch[\"Comments\"], padding=True, truncation=True, max_length=512)\n\ncategories_encoded = categories.map(tokenize, batched=True, batch_size=None)\nBATCH_SIZE = 16\n\ndef prepare_tf_dataset(dataset):\n    # Convert to tensorflow dataset\n    tf_dataset = tf.data.Dataset.from_tensor_slices(({\n        'input_ids': dataset['input_ids'],\n        'attention_mask': dataset['attention_mask']\n    }, dataset['Classification']))\n\n    return (tf_dataset.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE))\n\ntrain_dataset = prepare_tf_dataset(categories_encoded['train'])\nval_dataset = prepare_tf_dataset(categories_encoded['validation'])\ntest_dataset = prepare_tf_dataset(categories_encoded['test'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T19:59:40.988606Z","iopub.execute_input":"2025-05-07T19:59:40.988960Z","iopub.status.idle":"2025-05-07T19:59:54.911056Z","shell.execute_reply.started":"2025-05-07T19:59:40.988899Z","shell.execute_reply":"2025-05-07T19:59:54.910348Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d4db27f740e4d78bea395c564669ee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cbf776cd50942d28d99c594f65db0c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3378308c9b7404a9d16bf8acb673f78"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n\n# Train the model\nhistory = model.fit(\n    train_dataset,\n    epochs=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:01:43.826696Z","iopub.execute_input":"2025-05-07T20:01:43.827047Z","iopub.status.idle":"2025-05-07T20:16:52.273642Z","shell.execute_reply.started":"2025-05-07T20:01:43.827020Z","shell.execute_reply":"2025-05-07T20:16:52.272986Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n338/338 [==============================] - 194s 529ms/step - loss: 0.2777 - accuracy: 0.8931\nEpoch 2/5\n338/338 [==============================] - 179s 528ms/step - loss: 0.1783 - accuracy: 0.9419\nEpoch 3/5\n338/338 [==============================] - 179s 528ms/step - loss: 0.1197 - accuracy: 0.9607\nEpoch 4/5\n338/338 [==============================] - 179s 529ms/step - loss: 0.0725 - accuracy: 0.9785\nEpoch 5/5\n338/338 [==============================] - 179s 529ms/step - loss: 0.0520 - accuracy: 0.9856\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(test_dataset)\nprint(f\"Test accuracy: {test_accuracy:.4f}\")\n\n# Save the model in TensorFlow SavedModel format\n!mkdir \"/kaggle/working/distilbert_suggestion_model\"\ntf.saved_model.save(model, \"/kaggle/working/distilbert_suggestion_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:30:12.223213Z","iopub.execute_input":"2025-05-07T20:30:12.223519Z","iopub.status.idle":"2025-05-07T20:30:29.464439Z","shell.execute_reply.started":"2025-05-07T20:30:12.223493Z","shell.execute_reply":"2025-05-07T20:30:29.463386Z"}},"outputs":[{"name":"stdout","text":"19/19 [==============================] - 3s 165ms/step - loss: 0.2184 - accuracy: 0.9300\nTest accuracy: 0.9300\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Zip the model directory\n!zip -r /kaggle/working/distilbert_suggestion_model.zip /kaggle/working/distilbert_suggestion_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:30:29.466622Z","iopub.execute_input":"2025-05-07T20:30:29.466869Z","iopub.status.idle":"2025-05-07T20:31:03.945553Z","shell.execute_reply.started":"2025-05-07T20:30:29.466844Z","shell.execute_reply":"2025-05-07T20:31:03.944428Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/distilbert_suggestion_model/ (stored 0%)\n  adding: kaggle/working/distilbert_suggestion_model/saved_model.pb (deflated 92%)\n  adding: kaggle/working/distilbert_suggestion_model/variables/ (stored 0%)\n  adding: kaggle/working/distilbert_suggestion_model/variables/variables.data-00000-of-00001 (deflated 24%)\n  adding: kaggle/working/distilbert_suggestion_model/variables/variables.index (deflated 78%)\n  adding: kaggle/working/distilbert_suggestion_model/fingerprint.pb (stored 0%)\n  adding: kaggle/working/distilbert_suggestion_model/assets/ (stored 0%)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer\nimport numpy as np\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\nloaded_model = tf.saved_model.load(\"/kaggle/working/distilbert_suggestion_model\")\n\n# Model inference function\ninfer = loaded_model.signatures[\"serving_default\"]\n\n# Comments for prediction\ncomments_list = [\n    'misleading title click bait',\n    'kindly post video about claude 35 sonnet finetune and api full course video',\n    'superb excellent video keep it up',\n    'i liked the font you use in the thumbnail is it okay to share its name?',\n    'are these numbers even legit or just an exaggerated estimation?'\n]\n\n# Tokenize input comments\ninputs = tokenizer(comments_list, padding=True, truncation=True, max_length=512, return_tensors=\"tf\")\n\n# Run model inference\noutputs = infer(**inputs)\nlogits = outputs['logits'].numpy()\n\n# Define label mapping (0: Other, 1: Suggestion)\nlabel_mapping = {0: \"Other\", 1: \"Suggestion\"}\n\n# Convert logits to labels\npredictions = np.argmax(logits, axis=1)  \n\n# Display results\nfor index, pred in enumerate(predictions):\n    print(comments_list[index], \":\", label_mapping[pred])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T19:38:26.657981Z","iopub.execute_input":"2025-05-07T19:38:26.658307Z","iopub.status.idle":"2025-05-07T19:38:32.182943Z","shell.execute_reply.started":"2025-05-07T19:38:26.658281Z","shell.execute_reply":"2025-05-07T19:38:32.181816Z"}},"outputs":[{"name":"stdout","text":"misleading title click bait : Other\nkindly post video about claude 35 sonnet finetune and api full course video : Suggestion\nsuperb excellent video keep it up : Other\ni liked the font you use in the thumbnail is it okay to share its name? : Other\nare these numbers even legit or just an exaggerated estimation? : Other\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Path to your saved model\nmodel_path = \"/kaggle/working/bert_model_savedsuggestionmodel\"\n\n# Output zip path\nzip_output_path = \"/kaggle/working/bert_model_savedsuggestionmodel.zip\"\n\n# Zip the model directory\nwith zipfile.ZipFile(zip_output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(model_path):\n        for file in files:\n            filepath = os.path.join(root, file)\n            arcname = os.path.relpath(filepath, os.path.dirname(model_path))\n            zipf.write(filepath, arcname)\n\nprint(f\"✅ Model zipped and ready at: {zip_output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T07:29:22.434019Z","iopub.execute_input":"2025-04-21T07:29:22.434478Z","iopub.status.idle":"2025-04-21T07:29:55.442103Z","shell.execute_reply.started":"2025-04-21T07:29:22.434439Z","shell.execute_reply":"2025-04-21T07:29:55.441309Z"}},"outputs":[{"name":"stdout","text":"✅ Model zipped and ready at: /kaggle/working/bert_model_savedsuggestionmodel.zip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}